{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_function():\n",
    "    print 'all functions in this stage found in ssbio4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ESSENTIAL\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pickle\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from dateutil.parser import parse as dateparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_alignment2(a_id, a_seq, b_id, b_seq):\n",
    "    '''\n",
    "    Runs the needle alignment program and returns a raw text dump of the alignment\n",
    "    \n",
    "    Input:  a_id - sequence ID #1 (string)\n",
    "            a_seq - sequence #1 (string)\n",
    "            b_id - sequence ID #2 (string)\n",
    "            b_seq - sequence #2 (string)\n",
    "    Output: alignment_file - file name of alignment\n",
    "    \n",
    "    DEPENDENCIES:\n",
    "    get_alignment_allpos_df\n",
    "    '''\n",
    "    \n",
    "    from Bio.Emboss.Applications import NeedleCommandline\n",
    "    from Bio import AlignIO\n",
    "    import os.path\n",
    "\n",
    "    alignment_file = \"/tmp/%s_%s_align.txt\" % (a_id, b_id)\n",
    "\n",
    "    needle_cline = NeedleCommandline(asequence=\"asis::\"+a_seq, bsequence=\"asis::\"+b_seq, gapopen=10, gapextend=0.5, outfile=alignment_file)\n",
    "    stdout, stderr = needle_cline()\n",
    "    \n",
    "    return get_alignment_allpos_df(alignment_file, a_id, b_id)\n",
    "\n",
    "def get_corresponding_resnum(alignment_table, ref_id, ref_pos, new_id):\n",
    "    '''\n",
    "    Input: ref_ID, and reference position you are interested in that is in new_id\n",
    "    Output: Corresponding new resnum for that reference resnum\n",
    "    '''\n",
    "    id_a = alignment_table.id_a.unique()[0]\n",
    "    id_b = alignment_table.id_b.unique()[0]\n",
    "\n",
    "    if ref_id == id_a:\n",
    "        ref_id_col = 'id_a'\n",
    "        ref_pos_col = 'id_a_pos'\n",
    "        new_id_col = 'id_b'\n",
    "        new_pos_col = 'id_b_pos'\n",
    "    elif ref_id == id_b:\n",
    "        ref_id_col = 'id_b'\n",
    "        ref_pos_col = 'id_b_pos'\n",
    "        new_id_col = 'id_a'\n",
    "        new_pos_col = 'id_a_pos'\n",
    "    else:\n",
    "        print 'Reference ID not in alignment table!'\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return int(alignment_table[(alignment_table[ref_id_col] == ref_id) & (alignment_table[ref_pos_col] == ref_pos)][new_pos_col].values[0])\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "def get_alignment_allpos_df(alignment_file, a_seq_id=None, b_seq_id=None):\n",
    "    alignments = list(AlignIO.parse(alignment_file, \"emboss\"))\n",
    "\n",
    "    appender = defaultdict(dict)\n",
    "    idx = 0\n",
    "    for alignment in alignments:\n",
    "    #         if not switch:\n",
    "        if not a_seq_id:\n",
    "            a_seq_id = list(alignment)[0].id\n",
    "        a_seq = str(list(alignment)[0].seq)\n",
    "        if not b_seq_id:\n",
    "            b_seq_id = list(alignment)[1].id\n",
    "        b_seq = str(list(alignment)[1].seq)\n",
    "\n",
    "        a_idx = 1\n",
    "        b_idx = 1\n",
    "\n",
    "        for i, (a,b) in enumerate(zip(a_seq,b_seq)):\n",
    "            if a == b and a != '-' and b != '-':\n",
    "                aa_flag = 'match'\n",
    "            if a != b and a == '-' and b != '-':\n",
    "                aa_flag = 'insertion'\n",
    "            if a != b and a != '-' and b == '-':\n",
    "                aa_flag = 'deletion'\n",
    "            if a != b and a != '-' and b == 'X':\n",
    "                aa_flag = 'unresolved'\n",
    "            if a != b and b != '-' and a == 'X':\n",
    "                aa_flag = 'unresolved'\n",
    "            elif a != b and a != '-' and b != '-':\n",
    "                aa_flag = 'mutation'\n",
    "                \n",
    "            appender[idx]['id_a'] = a_seq_id\n",
    "            appender[idx]['id_b'] = b_seq_id\n",
    "            appender[idx]['type'] = aa_flag\n",
    "            \n",
    "            if aa_flag == 'match' or aa_flag == 'unresolved' or aa_flag == 'mutation':\n",
    "                appender[idx]['id_a_aa'] = a\n",
    "                appender[idx]['id_a_pos'] = a_idx\n",
    "                appender[idx]['id_b_aa'] = b\n",
    "                appender[idx]['id_b_pos'] = b_idx\n",
    "                a_idx += 1\n",
    "                b_idx += 1\n",
    "\n",
    "            if aa_flag == 'deletion':\n",
    "                appender[idx]['id_a_aa'] = a\n",
    "                appender[idx]['id_a_pos'] = a_idx\n",
    "                a_idx += 1\n",
    "\n",
    "            if aa_flag == 'insertion':\n",
    "                appender[idx]['id_b_aa'] = b\n",
    "                appender[idx]['id_b_pos'] = b_idx\n",
    "                b_idx += 1\n",
    "            \n",
    "            idx += 1\n",
    "\n",
    "    alignment_df = pd.DataFrame.from_dict(appender, orient='index')\n",
    "    alignment_df = alignment_df[['id_a', 'id_b', 'type', 'id_a_aa', 'id_a_pos', 'id_b_aa', 'id_b_pos']].fillna(value=np.nan)\n",
    "    \n",
    "    return alignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_struct_faa(path_to_file, file_name):\n",
    "    \n",
    "    from Bio.PDB.PDBParser import PDBParser\n",
    "    pdb_res = ''\n",
    "    \n",
    "    homol_file_name = path_to_file+file_name\n",
    "    if os.path.exists(homol_file_name):\n",
    "        file_path = homol_file_name\n",
    "    else:\n",
    "        file_path = None\n",
    "        print \"Wrong file path in code 'get_struct_faa' \"\n",
    "        \n",
    "    if file_path != None:\n",
    "\n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(file_name, file_path)\n",
    "        model = structure[0]\n",
    "        chains = [i.id for i in model.child_list]\n",
    "\n",
    "        for chain_id in chains:\n",
    "            chain = model[chain_id]\n",
    "            #print chain_id\n",
    "            residue_list = chain.child_list\n",
    "            for residue in list(residue_list):\n",
    "                if residue.id[0] == ' ':                \n",
    "                    #print residue.id[1], residue.resname.upper(), AAdict[str(residue.resname.upper())]\n",
    "                    try:\n",
    "                        pdb_res = pdb_res+ str(AAdict[str(residue.resname.upper())])\n",
    "                    except KeyError:\n",
    "                        if str(residue.resname.upper()) == 'HIE':\n",
    "                            pdb_res = pdb_res+'H'\n",
    "        \n",
    "        return pdb_res, chains, file_path\n",
    "    \n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Struct \n",
    "from Bio import PDB\n",
    "\n",
    "#calculate combinations\n",
    "def combinations(iterable, r):\n",
    "    # combinations('ABCD', 2) --> AB AC AD BC BD CD\n",
    "    # combinations(range(4), 3) --> 012 013 023 123\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    if r > n:\n",
    "        return\n",
    "    indices = range(r)\n",
    "    yield list(pool[i] for i in indices)\n",
    "    while True:\n",
    "        for i in reversed(range(r)):\n",
    "            if indices[i] != i + n - r:\n",
    "                break\n",
    "        else:\n",
    "            return\n",
    "        indices[i] += 1\n",
    "        for j in range(i+1, r):\n",
    "            indices[j] = indices[j-1] + 1\n",
    "        yield list(pool[i] for i in indices)\n",
    "                \n",
    "#calculate the magnitude of distance vector\n",
    "def magni(a,b,c):\n",
    "    return pow((pow(a,2)+pow(b,2)+pow(c,2)),1.0/2.0)\n",
    " \n",
    "def generate_distance_matrices(struct_dir, df):\n",
    "    closelist=[]\n",
    "\n",
    "    for i in df.gene.unique():\n",
    "        if len(df[df.gene==i])>=2:\n",
    "            filepath=df[df.gene==i].pdb_file.values[0]\n",
    "            s= Struct.read(struct_dir+filepath)\n",
    "            model=s[0]\n",
    "            res_list = PDB.Selection.unfold_entities(model, 'R')\n",
    "            pdb_start_list=df[df.gene==i].p_pdb_aa.tolist()\n",
    "            ires_list=[]\n",
    "            coord_list=[]\n",
    "            for j in res_list:\n",
    "                if j.id[1] in pdb_start_list and j.resname!='HOH':\n",
    "                    ires_list.append(j)\n",
    "            paired=combinations(ires_list,2)\n",
    "            for k in paired:\n",
    "                chainA=PDB.Selection.unfold_entities(k[0], 'C')[0]\n",
    "                chainB=PDB.Selection.unfold_entities(k[1], 'C')[0]\n",
    "                vec=list(np.array([x.get_coord() for x in k[0]]).mean(axis=0)-np.array([x.get_coord() for x in k[1]]).mean(axis=0))\n",
    "                distance=magni(vec[0],vec[1],vec[2])\n",
    "                if distance<=35: #cut off \n",
    "                     closelist.append([i,filename,chainA.id,chainB.id,k[0].id[1],k[1].id[1],k[0].resname,k[1].resname,distance])\n",
    "                        \n",
    "    df=pd.DataFrame(closelist)\n",
    "    df.columns=['gene','pdb','chainA','chainB','locationA','locationB','resA','resB','distance']\n",
    "    return df        \n",
    "\n",
    "def calculate_res_distance(gene, res_1, res_2, df, struct_dir):\n",
    "    \n",
    "    filepath=df[df.gene==gene].pdb_file.values[0]\n",
    "    s= Struct.read(struct_dir+filepath)\n",
    "    model=s[0]\n",
    "    res_list = PDB.Selection.unfold_entities(model, 'R')\n",
    "    \n",
    "    ires_list=[]\n",
    "    res_chk_1 = ''\n",
    "    res_chk_2 = ''\n",
    "    name_chk_1 = ''\n",
    "    name_chk_2 = ''\n",
    "    for j in res_list:\n",
    "        if j.id[1] in [res_1,res_2] and j.resname!='HOH':\n",
    "            ires_list.append(j)\n",
    "            #print j.id[1], j.resname, AAdict[j.resname]\n",
    "            if res_chk_1 == '' and res_chk_2 == '':\n",
    "                res_chk_1 = j.id[1]\n",
    "                name_chk_1 = AAdict[j.resname]\n",
    "            else:\n",
    "                res_chk_2 = j.id[1]\n",
    "                name_chk_2 = AAdict[j.resname]\n",
    "                \n",
    "    paired=combinations(ires_list,2)\n",
    "    try:\n",
    "        for k in paired:\n",
    "            chainA=PDB.Selection.unfold_entities(k[0], 'C')[0]\n",
    "            chainB=PDB.Selection.unfold_entities(k[1], 'C')[0]\n",
    "            vec=list(np.array([x.get_coord() for x in k[0]]).mean(axis=0)-np.array([x.get_coord() for x in k[1]]).mean(axis=0))\n",
    "            distance=magni(vec[0],vec[1],vec[2])\n",
    "            \n",
    "        return (res_chk_1,name_chk_1,res_chk_2,name_chk_2, distance, len(res_list))\n",
    "    except UnboundLocalError:\n",
    "        return \"Unknown interaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strandict={\n",
    "'iAPECO1_1312':'EP',\n",
    " 'ic_1306':'EP',\n",
    " 'iE2348C_1286':'EP',\n",
    " 'iEC042_1314':'EP',\n",
    " 'iEC55989_1330':'IP',\n",
    " 'iECABU_c1320':'EP',\n",
    " 'iECB_1328':'CM',\n",
    " 'iEcE24377_1341':'IP',\n",
    " 'iECH74115_1262':'IP',\n",
    " 'iECIAI1_1343':'IP',\n",
    " 'iECIAI39_1322':'EP',\n",
    " 'iECNA114_1301':'EP',\n",
    " 'iECO103_1326':'IP',\n",
    " 'iECO111_1330':'IP',\n",
    " 'iECO26_1355':'IP',\n",
    " 'iECOK1_1307':'EP',\n",
    " 'iEcolC_1368':'CM',\n",
    " 'iECP_1309':'EP',\n",
    " 'iECs_1301':'IP',\n",
    " 'iECS88_1305':'EP',\n",
    " 'iECSE_1348':'IP',\n",
    " 'iECSF_1327':'EP',\n",
    " 'iEcSMS35_1347':'EP',\n",
    " 'iECSP_1301':'IP',\n",
    " 'iECUMN_1333':'EP',\n",
    " 'iETEC_1333':'CM',\n",
    " 'iG2583_1286':'IP',\n",
    " 'iLF82_1304':'EP',\n",
    " 'iNRG857_1313':'EP',\n",
    " 'iS_1188':'SG',\n",
    " 'iSbBS512_1146':'SG',\n",
    " 'iSBO_1134':'SG',\n",
    " 'iSDY_1059':'SG',\n",
    " 'iSFV_1184':'SG',\n",
    " 'iSFxv_1172':'SG',\n",
    " 'iSSON_1240':'SG',\n",
    " 'iUMNK88_1353':'CM',\n",
    " 'iUTI89_1310':'EP',\n",
    " 'iBWG_1329':'CM',\n",
    " 'iECDH10B_1368':'CM',\n",
    " 'iEcDH1_1363':'CM',\n",
    " 'iJO1366':'CM',\n",
    " 'iECDH1ME8569_1439':'CM'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_residue_depth(res,gene_name,df):\n",
    "    for i in ast.literal_eval(df[df.gene == gene_name].msms.values[0]):\n",
    "        if i[1] == res:\n",
    "            return i[2], i[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# + = red, - = blue, hydrophobic = yellow, polar = green, neutral = grey\n",
    "from brewer2mpl import * \n",
    "\n",
    "positive_charge_colors = brewer2mpl.get_map('reds', 'sequential', 8).mpl_colors\n",
    "negative_charge_colors = brewer2mpl.get_map('Blues', 'sequential', 8).mpl_colors\n",
    "hydrophobic_colors = brewer2mpl.get_map('greens', 'sequential', 8).mpl_colors\n",
    "polar_colors = brewer2mpl.get_map('purples', 'sequential', 8).mpl_colors\n",
    "neutral_colors = brewer2mpl.get_map('greys', 'sequential', 8).mpl_colors\n",
    "special_colors = brewer2mpl.get_map('YlOrBr', 'sequential', 8).mpl_colors\n",
    "\n",
    "color_dict = {'R':positive_charge_colors[4],\n",
    " 'K':positive_charge_colors[5],\n",
    " 'H':positive_charge_colors[6],\n",
    " 'D':negative_charge_colors[5],\n",
    " 'E':negative_charge_colors[7],\n",
    " 'S':polar_colors[3],\n",
    " 'T':polar_colors[4],\n",
    " 'N':polar_colors[5],\n",
    " 'Q':polar_colors[6],\n",
    " 'C':special_colors[2],\n",
    " 'U':special_colors[1],\n",
    " 'P':special_colors[3],\n",
    " 'G':neutral_colors[2],\n",
    " 'A':neutral_colors[5],\n",
    " 'I':hydrophobic_colors[7],\n",
    " 'L':hydrophobic_colors[6],\n",
    " 'M':hydrophobic_colors[5],\n",
    " 'F':hydrophobic_colors[4],\n",
    " 'W':hydrophobic_colors[3],\n",
    " 'V':hydrophobic_colors[2],\n",
    " 'Y':hydrophobic_colors[1],\n",
    " }\n",
    "\n",
    "color_dict_course = [positive_charge_colors[6],\n",
    "                     negative_charge_colors[7],\n",
    "                     polar_colors[6],\n",
    "                     hydrophobic_colors[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_mutations_per_gene(df):\n",
    "    dplow=df[df.ca_res_depth <4]\n",
    "    dpmed=df[df.ca_res_depth >=4][df.ca_res_depth <7.5]\n",
    "    dphigh=df[df.ca_res_depth >=7.5]\n",
    "\n",
    "    dplowdn=dplow.drop_duplicates(cols=['p_pdb_aa'])\n",
    "    dpmeddn=dpmed.drop_duplicates(cols=['p_pdb_aa'])\n",
    "    dphighdn=dphigh.drop_duplicates(cols=['p_pdb_aa'])\n",
    "\n",
    "    lowlist=dplowdn.ix[:,10:37].mean().values.tolist()\n",
    "    medlist=dpmeddn.ix[:,10:37].mean().values.tolist()\n",
    "    highlist=dphighdn.ix[:,10:37].mean().values.tolist()\n",
    "\n",
    "    lmh=pd.DataFrame([lowlist,medlist,highlist])\n",
    "    lmh.columns=[u'R', u'H', u'K', u'D', u'E', u'S', u'T', u'N', u'Q', u'C', u'U', u'Y', u'P', u'G', u'A', u'I', u'L', u'M', u'F', u'W', u'V', u'X', u'positive', u'negative', u'polar', u'nonpolar', u'unknown']\n",
    "    lmh.index=['surface','med','deep']\n",
    "\n",
    "    f = plt.figure()\n",
    "    lmh[['positive','negative','polar','nonpolar']].plot(kind='bar', ax=f.gca(),colors = color_dict_course,alpha=0.5)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    f.suptitle('gene: %s'%str(df.gene.unique()[0]))\n",
    "    return lmh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
